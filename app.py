import streamlit as st
import os
import json
import time
import requests
import random
import shutil
import math
import PyPDF2
import uuid
import textwrap
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import edge_tts
import asyncio

# --- æ ¸å¿ƒä¿®æ­£ï¼šäº‘ç«¯å¿…é¡»ä» moviepy.editor å¯¼å…¥ ---
from moviepy.editor import (
    ImageClip, 
    AudioFileClip, 
    VideoFileClip, # æ–°å¢ï¼šè¯»å–è§†é¢‘æ–‡ä»¶
    concatenate_videoclips, 
    CompositeAudioClip,
    concatenate_audioclips
)

# --- 0. å…¨å±€é…ç½® ---
st.set_page_config(page_title="AI è§†é¢‘å·¥åŠ (ç¡¬ç›˜ç¼“å­˜ç‰ˆ)", page_icon="ğŸ’¾", layout="wide")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
AUDIO_DIR = os.path.join(BASE_DIR, "audio_files")
IMAGE_DIR = os.path.join(BASE_DIR, "image_files")
TEMP_DIR = os.path.join(BASE_DIR, "temp_clips") # ä¸´æ—¶è§†é¢‘å­˜æ”¾åŒº
BGM_DIR = os.path.join(BASE_DIR, "bgm_assets")
OUTPUT_VIDEO = os.path.join(BASE_DIR, "final_output.mp4")
FONT_FILENAME = "font.ttf"
FONT_PATH = os.path.join(BASE_DIR, FONT_FILENAME)

# æš´åŠ›æ¸…ç†é‡å»ºç›®å½•
if os.path.exists(TEMP_DIR): shutil.rmtree(TEMP_DIR)
for d in [AUDIO_DIR, IMAGE_DIR, BGM_DIR, TEMP_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# --- 1. èµ„æºåˆå§‹åŒ– ---
def download_file(url, filepath):
    if os.path.exists(filepath): return True
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers, stream=True, timeout=30)
        if resp.status_code == 200:
            with open(filepath, 'wb') as f:
                for chunk in resp.iter_content(chunk_size=8192): f.write(chunk)
            return True
    except: pass
    return False

def init_resources():
    font_url = "https://raw.githubusercontent.com/StellarCN/scp_zh/master/fonts/SimHei.ttf"
    if not os.path.exists(FONT_PATH):
        download_file(font_url, FONT_PATH)

    bgm_list = {
        "tech.mp3": "https://cdn.pixabay.com/download/audio/2022/03/15/audio_c8c8a73467.mp3",
        "epic.mp3": "https://cdn.pixabay.com/download/audio/2022/03/10/audio_c8c8a73467.mp3"
    }
    for name, url in bgm_list.items():
        path = os.path.join(BGM_DIR, name)
        if not os.path.exists(path): download_file(url, path)

init_resources()

# --- 2. åŸºç¡€åŠŸèƒ½ ---
def read_pdf(file):
    try:
        reader = PyPDF2.PdfReader(file)
        text = ""
        for page in reader.pages[:20]: text += page.extract_text()
        return text
    except: return None

# --- 3. AI é€»è¾‘ ---
def generate_script(text, api_key, lang_mode):
    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    
    lang_rule = "Simplified Chinese" if lang_mode == "ä¸­æ–‡" else "English"

    system_prompt = f"""
    Video Director Mode.
    1. Narration: {lang_rule}. Concise.
    2. Image: English, photorealistic, 8k. NO TEXT.
    3. JSON Only.
    
    {{
        "bgm": "tech",
        "scenes": [
            {{"narration": "...", "image_prompt": "..."}}
        ]
    }}
    """
    
    try:
        resp = requests.post(url, json={
            "model": "deepseek-ai/DeepSeek-V3",
            "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": text[:8000]}],
            "response_format": {"type": "json_object"}
        }, headers=headers, timeout=120)
        return json.loads(resp.json()['choices'][0]['message']['content'])
    except: return None

async def _gen_assets(script, voice, key, run_id):
    for i, scene in enumerate(script):
        out = os.path.join(AUDIO_DIR, f"{i}_{run_id}.mp3")
        try:
            communicate = edge_tts.Communicate(scene['narration'], voice)
            await communicate.save(out)
        except: pass
        
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    for i, scene in enumerate(script):
        out = os.path.join(IMAGE_DIR, f"{i}_{run_id}.jpg")
        try:
            resp = requests.post(
                "https://api.siliconflow.cn/v1/images/generations",
                json={"model": "black-forest-labs/FLUX.1-schnell", "prompt": scene['image_prompt'] + " (no text)", "image_size": "1024x576", "num_inference_steps": 4, "seed": random.randint(0, 1e9)},
                headers=headers, timeout=30
            )
            if resp.status_code == 200:
                with open(out, 'wb') as f: f.write(requests.get(resp.json()['images'][0]['url']).content)
            time.sleep(0.5)
        except: pass

def gen_assets_sync(script, voice, key, run_id):
    v = "zh-CN-YunxiNeural" if voice == "ä¸­æ–‡" else "en-US-GuyNeural"
    asyncio.run(_gen_assets(script, v, key, run_id))

# --- 4. æ¸²æŸ“ (ç¡¬ç›˜ç¼“å­˜ + å†…å­˜é‡Šæ”¾) ---
def draw_subtitle(img_path, text):
    if not os.path.exists(img_path): return None
    try:
        img = Image.open(img_path).convert("RGBA")
        # ğŸ”´ å¼ºåˆ¶ 480P (854x480)ï¼Œè¿™æ˜¯äº‘ç«¯ä¸å¡æ­»çš„é»„é‡‘åˆ†è¾¨ç‡
        img = img.resize((854, 480), Image.LANCZOS)
        draw = ImageDraw.Draw(img)
        
        try: font = ImageFont.truetype(FONT_FILENAME, 25) 
        except: font = ImageFont.load_default()
        
        w_limit = 28 if any('\u4e00' <= c <= '\u9fff' for c in text) else 45
        text = textwrap.fill(text, width=w_limit)
        
        bbox = draw.multiline_textbbox((0,0), text, font=font, align="center")
        tw, th = bbox[2]-bbox[0], bbox[3]-bbox[1]
        x, y = (854-tw)//2, 480-th-30
        
        draw.rectangle([x-10, y-10, x+tw+10, y+th+10], fill=(0,0,0,160))
        draw.multiline_text((x, y), text, font=font, fill='white', align="center")
        
        return np.array(img.convert("RGB"))
    except: return None

def render(script, bgm_file, run_id):
    temp_files = [] # å­˜å‚¨ä¸´æ—¶å°è§†é¢‘è·¯å¾„
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    total = len(script)
    
    # 1. é€ä¸ªç”Ÿæˆä¸´æ—¶è§†é¢‘æ–‡ä»¶ (æ¯åšä¸€ä¸ªæ¸…ç†ä¸€ä¸ªå†…å­˜)
    for i, scene in enumerate(script):
        status_text.text(f"ğŸ”¨ æ­£åœ¨ç¡¬ç›˜ç”Ÿæˆç‰‡æ®µ: {i+1}/{total} (å†…å­˜å·²é‡Šæ”¾)...")
        
        aud = os.path.join(AUDIO_DIR, f"{i}_{run_id}.mp3")
        img = os.path.join(IMAGE_DIR, f"{i}_{run_id}.jpg")
        temp_out = os.path.join(TEMP_DIR, f"clip_{i}_{run_id}.mp4")
        
        if os.path.exists(aud) and os.path.exists(img):
            try:
                # ç”Ÿæˆå•ä¸ª Clip
                audio = AudioFileClip(aud)
                img_arr = draw_subtitle(img, scene['narration'])
                
                if img_arr is not None:
                    clip = ImageClip(img_arr).set_duration(audio.duration + 0.2).set_audio(audio)
                    
                    # ğŸ”´ ç«‹å³å†™å…¥ç¡¬ç›˜ï¼ä¸è¦ç•™åœ¨å†…å­˜é‡Œï¼
                    # fps=8 æä½å¸§ç‡ä¿è¯é€Ÿåº¦
                    clip.write_videofile(temp_out, fps=8, codec="libx264", audio_codec="aac", preset="ultrafast", verbose=False, logger=None)
                    
                    # æ˜¾å¼å…³é—­ï¼Œé‡Šæ”¾å†…å­˜å¥æŸ„
                    clip.close()
                    audio.close()
                    del clip
                    del audio
                    
                    temp_files.append(temp_out)
            except Exception as e:
                print(f"ç‰‡æ®µ {i} å¤±è´¥: {e}")
                
        progress_bar.progress((i+1)/total * 0.8)
    
    if not temp_files: return None
    
    # 2. æœ€ç»ˆç¼åˆ (Chain Mode æé€Ÿæ¨¡å¼)
    status_text.text("ğŸ”— æ­£åœ¨ç¼åˆç¡¬ç›˜æ–‡ä»¶...")
    
    # è¯»å–æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
    clips = [VideoFileClip(f) for f in temp_files]
    final = concatenate_videoclips(clips, method="chain")
    
    # BGM ç®€å•æ··éŸ³
    if bgm_file and os.path.exists(bgm_file):
        try:
            bgm = AudioFileClip(bgm_file)
            if bgm.duration < final.duration:
                loops = math.ceil(final.duration/bgm.duration)+1
                bgm = concatenate_audioclips([bgm] * loops)
            bgm = bgm.set_duration(final.duration).volumex(0.15)
            final.audio = CompositeAudioClip([final.audio, bgm])
        except: pass
    
    status_text.text("ğŸ’¾ æœ€ç»ˆå¯¼å‡º...")
    final.write_videofile(
        OUTPUT_VIDEO, 
        fps=8, 
        codec="libx264", 
        audio_codec="aac", 
        preset="ultrafast",
        threads=1
    )
    
    # æ¸…ç†æ‰€æœ‰å¥æŸ„
    final.close()
    for c in clips: c.close()
    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    try: shutil.rmtree(TEMP_DIR)
    except: pass
    
    progress_bar.progress(1.0)
    status_text.empty()
    return OUTPUT_VIDEO

# --- 5. UI ---
with st.sidebar:
    st.header("é…ç½®")
    key = st.text_input("SiliconFlow Key", type="password")
    lang = st.radio("ç›®æ ‡è¯­è¨€", ["ä¸­æ–‡", "è‹±æ–‡"])
    voice = st.selectbox("é…éŸ³", ["ä¸­æ–‡ç”·å£°", "ä¸­æ–‡å¥³å£°"] if lang=="ä¸­æ–‡" else ["English Male", "English Female"])
    bgm_up = st.file_uploader("BGM", type="mp3")

st.title("ğŸ’¾ AI è§†é¢‘å·¥åŠ (ç¡¬ç›˜ç¼“å­˜ç‰ˆ)")

tab1, tab2 = st.tabs(["PDF", "æ–‡æœ¬"])
raw = ""
with tab1:
    f = st.file_uploader("æ–‡ä»¶", type="pdf")
    if f: raw = read_pdf(f)
with tab2:
    t = st.text_area("æ–‡æœ¬", height=200)
    if t: raw = t

if st.button("ğŸš€ ç«‹å³ç”Ÿæˆ", type="primary"):
    if not key or not raw:
        st.error("ç¼ºå†…å®¹")
    else:
        run_id = str(uuid.uuid4())[:6]
        
        with st.spinner("1/3 å†™å‰§æœ¬..."):
            data = generate_script(raw, key, lang)
        
        if not data: st.stop()
        
        with st.spinner("2/3 åšç´ æ..."):
            gen_assets_sync(data['scenes'], voice, key, run_id)
            
        bgm = None
        if bgm_up:
            bgm = "temp.mp3"
            with open(bgm, "wb") as f: f.write(bgm_up.getbuffer())
        else:
            p = os.path.join(BGM_DIR, "tech.mp3")
            if os.path.exists(p): bgm = p
            
        v = render(data['scenes'], bgm, run_id)
        if v:
            st.success("âœ… å®Œæˆï¼")
            st.video(v)
